{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_nmt.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgC8SXkEKXKs8cVS/hJSUA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliwagdy2580/NLP/blob/main/seq2seq%2Battention_nmt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsLSt1W9pDG-"
      },
      "source": [
        "# Seq2seq models tutorial\n",
        "\n",
        "In this tutorial we go through the details of building seq2seq models in Keras, and explore different models for different problem setups.\n",
        "\n",
        "This tutorial includes:\n",
        "- Adding attention + visualization: Luong \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k2YmYoKnnBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bcef5b9-0597-4bba-fb0a-e6098932bf7e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from keras.layers import Input, LSTM, Embedding, Dense, Bidirectional, Concatenate, Dot, Activation, TimeDistributed\n",
        "from keras.models import Model\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgYRKLVHriWW"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADuphMW9q6S5",
        "outputId": "ebc2ad3d-6d66-4875-e129-424b0516bd55"
      },
      "source": [
        "!wget http://www.manythings.org/anki/fra-eng.zip\n",
        "!unzip fra-eng.zip -d fra-eng\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-04 16:20:56--  http://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 172.67.186.54, 104.21.92.44, 2606:4700:3033::ac43:ba36, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|172.67.186.54|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6451478 (6.2M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   6.15M  5.40MB/s    in 1.1s    \n",
            "\n",
            "2021-09-04 16:20:58 (5.40 MB/s) - ‘fra-eng.zip’ saved [6451478/6451478]\n",
            "\n",
            "Archive:  fra-eng.zip\n",
            "  inflating: fra-eng/_about.txt      \n",
            "  inflating: fra-eng/fra.txt         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyMmolmprkKR"
      },
      "source": [
        "data_path = 'fra-eng/fra.txt'\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "inputs = []\n",
        "targets = []\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "  input, target, _ = line.split('\\t')  \n",
        "  inputs.append(input)\n",
        "  targets.append(target)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0lv_lKbslYy"
      },
      "source": [
        "lines=pd.DataFrame({'input':inputs,'target':targets})"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf9UEEjrtiO4"
      },
      "source": [
        "num_samples = 10000\n",
        "lines = lines[0:num_samples]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js_FE4xtG_KA",
        "outputId": "94ebd5a2-ad8b-4aeb-c4c4-47d2bac6faeb"
      },
      "source": [
        "lines.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "oicoj3SyG_HF",
        "outputId": "5da95563-6c65-4485-a602-0634a854f202"
      },
      "source": [
        "lines.head(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Va !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Marche.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Bouge !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Prenez vos jambes à vos cous !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Run!</td>\n",
              "      <td>File !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Filez !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  input                          target\n",
              "0   Go.                            Va !\n",
              "1   Go.                         Marche.\n",
              "2   Go.                         Bouge !\n",
              "3   Hi.                         Salut !\n",
              "4   Hi.                          Salut.\n",
              "5  Run!                         Cours !\n",
              "6  Run!                        Courez !\n",
              "7  Run!  Prenez vos jambes à vos cous !\n",
              "8  Run!                          File !\n",
              "9  Run!                         Filez !"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qH0UyxZKezV"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6mjJU6-17dt"
      },
      "source": [
        "def cleanup(lines):\n",
        "  # Since we work on word level, if we normalize the text to lower case, this will reduce the vocabulary. It's easy to recover the case later. \n",
        "  lines.input=lines.input.apply(lambda x: x.lower())\n",
        "  lines.target=lines.target.apply(lambda x: x.lower())\n",
        "\n",
        "  # To help the model capture the word separations, mark the comma with special token:\n",
        "  lines.input=lines.input.apply(lambda x:re.sub(\"'\",'',x)).apply(lambda x: re.sub(\",\", ' COMMA', x))\n",
        "  lines.target=lines.target.apply(lambda x:re.sub(\"'\",'',x)).apply(lambda x: re.sub(\",\", ' COMMA', x))\n",
        "\n",
        "  # Clean up punctuations and digits. Such special chars are common to both domains, and can just be copied with no error.\n",
        "  exclude = set(string.punctuation)\n",
        "  lines.input=lines.input.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "  lines.target=lines.target.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "\n",
        "  remove_digits = str.maketrans('', '', digits)\n",
        "  lines.input=lines.input.apply(lambda x: x.translate(remove_digits))\n",
        "  lines.target=lines.target.apply(lambda x: x.translate(remove_digits))\n",
        "  #return lines\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3NWR2S0FnGl"
      },
      "source": [
        "st_tok='START_'\n",
        "end_tok='_END'\n",
        "def data_prep(lines):\n",
        "  cleanup(lines)\n",
        "  lines.target=lines.target.apply(lambda x: st_tok + ' ' + x + ' ' + end_tok)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKJpTFC9KjIt"
      },
      "source": [
        "To help the model identiy the start and end of sequence, we mark them by special tokens. This will help the decoding process later:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBUYKRpqFnJc"
      },
      "source": [
        "data_prep(lines)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "zjllZhyqKE1c",
        "outputId": "da1fae42-a583-4a70-cd02-f9ac22701443"
      },
      "source": [
        "lines.head(10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>go</td>\n",
              "      <td>START_ va  _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>go</td>\n",
              "      <td>START_ marche _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>go</td>\n",
              "      <td>START_ bouge  _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hi</td>\n",
              "      <td>START_ salut  _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hi</td>\n",
              "      <td>START_ salut _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>run</td>\n",
              "      <td>START_ cours  _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>run</td>\n",
              "      <td>START_ courez  _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>run</td>\n",
              "      <td>START_ prenez vos jambes à vos cous  _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>run</td>\n",
              "      <td>START_ file  _END</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>run</td>\n",
              "      <td>START_ filez  _END</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  input                                     target\n",
              "0    go                            START_ va  _END\n",
              "1    go                         START_ marche _END\n",
              "2    go                         START_ bouge  _END\n",
              "3    hi                         START_ salut  _END\n",
              "4    hi                          START_ salut _END\n",
              "5   run                         START_ cours  _END\n",
              "6   run                        START_ courez  _END\n",
              "7   run  START_ prenez vos jambes à vos cous  _END\n",
              "8   run                          START_ file  _END\n",
              "9   run                         START_ filez  _END"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_Ple2P5KmVN"
      },
      "source": [
        "# Word level model (word2word)\n",
        "\n",
        "In this section we process the text at the word level, both for `input` and `target` domains."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh5nJrDqFnML"
      },
      "source": [
        "def tok_split_word2word(data):\n",
        "  return data.split()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ealuqtopFtrc"
      },
      "source": [
        "tok_split_fn = tok_split_word2word"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgUaBMaMFtwi"
      },
      "source": [
        "def data_stats(lines, input_tok_split_fn, target_tok_split_fn):\n",
        "  input_tokens=set()\n",
        "  for line in lines.input:\n",
        "      for tok in input_tok_split_fn(line):\n",
        "          if tok not in input_tokens:\n",
        "              input_tokens.add(tok)\n",
        "      \n",
        "  target_tokens=set()\n",
        "  for line in lines.target:\n",
        "      for tok in target_tok_split_fn(line):\n",
        "          if tok not in target_tokens:\n",
        "              target_tokens.add(tok)\n",
        "  input_tokens = sorted(list(input_tokens))\n",
        "  target_tokens = sorted(list(target_tokens))\n",
        "\n",
        "  num_encoder_tokens = len(input_tokens)\n",
        "  num_decoder_tokens = len(target_tokens)\n",
        "  max_encoder_seq_length = np.max([len(input_tok_split_fn(l)) for l in lines.input])\n",
        "  max_decoder_seq_length = np.max([len(target_tok_split_fn(l)) for l in lines.target])\n",
        "\n",
        "  return input_tokens, target_tokens, num_encoder_tokens, num_decoder_tokens, max_encoder_seq_length, max_decoder_seq_length\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l28ARUZ_SVaR",
        "outputId": "8c910f9f-84d8-4c6d-8261-720ffe2c5fdb"
      },
      "source": [
        "input_tokens,target_tokens,num_encoder_tokens,num_decoder_tokens,max_encoder_seq_length,max_decoder_seq_length=data_stats(lines,input_tok_split_fn=tok_split_fn,target_tok_split_fn=tok_split_fn)\n",
        "print('Number of samples:', len(lines))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 10000\n",
            "Number of unique input tokens: 2017\n",
            "Number of unique output tokens: 4472\n",
            "Max sequence length for inputs: 5\n",
            "Max sequence length for outputs: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCDYd0E0Vgzm"
      },
      "source": [
        "#Vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAn2yXnlVj3h"
      },
      "source": [
        "When building our vocab, we should keep a special entry for the PAD \n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "token, _always_ at the entry 0 of the vocab table. Of course this only happens when we pad with 0's. In general the padded token should be reserved, and NEVER used by any other token (otherwise we won't tell the difference between REAL 0 and PAD 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt_7KwGPFtyg"
      },
      "source": [
        "pad_tok = 'PAD'\n",
        "sep_tok = ' '\n",
        "special_tokens = [pad_tok, sep_tok, st_tok, end_tok] \n",
        "num_encoder_tokens += len(special_tokens)\n",
        "num_decoder_tokens += len(special_tokens)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPbomiK8FyZk"
      },
      "source": [
        "\n",
        "def vocab(input_tokens, target_tokens):\n",
        "  \n",
        "  input_token_index = {}\n",
        "  target_token_index = {}\n",
        "  for i,tok in enumerate(special_tokens):\n",
        "    input_token_index[tok] = i\n",
        "    target_token_index[tok] = i \n",
        "\n",
        "  offset = len(special_tokens)\n",
        "  for i, tok in enumerate(input_tokens):\n",
        "    input_token_index[tok] = i+offset\n",
        "\n",
        "  for i, tok in enumerate(target_tokens):\n",
        "    target_token_index[tok] = i+offset\n",
        "   \n",
        "  # Reverse-lookup token index to decode sequences back to something readable.\n",
        "  reverse_input_tok_index = dict(\n",
        "      (i, tok) for tok, i in input_token_index.items())\n",
        "  reverse_target_tok_index = dict(\n",
        "      (i, tok) for tok, i in target_token_index.items())\n",
        "  return input_token_index, target_token_index, reverse_input_tok_index, reverse_target_tok_index"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMug8-dTFycU"
      },
      "source": [
        "input_token_index, target_token_index, reverse_input_tok_index, reverse_target_tok_index = vocab(input_tokens, target_tokens)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC1lu-ppY1JI"
      },
      "source": [
        "# Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJbnztywY1L3"
      },
      "source": [
        "Also, when we vectorize, if we pad 0 (or any token), we need to set the corresponding target.\n",
        "\n",
        "Below, we should set all `decoder_target_data` to the OHE corresponding the entry 0 (or whatever entry of PAD).\n",
        "\n",
        "For example, if we pad with 0, and 0 is the first entry in vocab, then it's `decoder_target_data` must be [1,0,0,....0].\n",
        "However, this is not needed if we use `mask_zero` in `Embedding`, or using a masking layer with LSTM, because those values wont be fed fwd anyway, and will not be considered in loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjpfqwRlF3ab"
      },
      "source": [
        "max_encoder_seq_length = 16\n",
        "max_decoder_seq_length = 16"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8npCTEaGF3c9"
      },
      "source": [
        "def init_model_inputs(lines, max_encoder_seq_length, max_decoder_seq_length, num_decoder_tokens):\n",
        "  encoder_input_data = np.zeros(\n",
        "      (len(lines.input), max_encoder_seq_length),\n",
        "      dtype='float32')\n",
        "  decoder_input_data = np.zeros(\n",
        "      (len(lines.target), max_decoder_seq_length),\n",
        "      dtype='float32')\n",
        "  decoder_target_data = np.zeros(\n",
        "      (len(lines.target), max_decoder_seq_length, num_decoder_tokens),\n",
        "      dtype='float32')\n",
        "  \n",
        "  return encoder_input_data, decoder_input_data, decoder_target_data"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyfeW6UAK1ZQ"
      },
      "source": [
        "  encoder_input_data, decoder_input_data, decoder_target_data = init_model_inputs(lines, max_encoder_seq_length, max_decoder_seq_length, num_decoder_tokens)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zZLDOeifMyv"
      },
      "source": [
        "def vectorize(lines, max_encoder_seq_length, max_decoder_seq_length, num_decoder_tokens, input_tok_split_fn, target_tok_split_fn):\n",
        "  encoder_input_data, decoder_input_data, decoder_target_data = init_model_inputs(lines, max_encoder_seq_length, max_decoder_seq_length, num_decoder_tokens)\n",
        "  for i, (input_text, target_text) in enumerate(zip(lines.input, lines.target)):\n",
        "      for t, tok in enumerate(input_tok_split_fn(input_text)):\n",
        "          encoder_input_data[i, t] = input_token_index[tok]\n",
        "      encoder_input_data[i, t+1:] = input_token_index[pad_tok]\n",
        "      for t, tok in enumerate(target_tok_split_fn(target_text)):\n",
        "          # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "          decoder_input_data[i, t] = target_token_index[tok]         \n",
        "          if t > 0:\n",
        "              # decoder_target_data will be ahead by one timestep\n",
        "              # and will not include the start character.\n",
        "              decoder_target_data[i, t - 1, target_token_index[tok]] = 1.\n",
        "      decoder_input_data[i, t+1:] = target_token_index[pad_tok] \n",
        "      decoder_target_data[i, t:, target_token_index[pad_tok]] = 1.          \n",
        "              \n",
        "  return encoder_input_data, decoder_input_data, decoder_target_data              "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhSOAQU5F3mM"
      },
      "source": [
        "encoder_input_data, decoder_input_data, decoder_target_data  = vectorize(lines, max_encoder_seq_length, max_decoder_seq_length, num_decoder_tokens, input_tok_split_fn=tok_split_fn, target_tok_split_fn=tok_split_fn)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4z4mLCTlfec"
      },
      "source": [
        "# seq2seq + Attention\n",
        "\n",
        "The vanilla seq2seq suffers a severe drawback, all the decoded outputs are initiated from the _final_ internal state of the encoder. The objective is to mimic the reading process in humans, where the whole sequence is comprehended first, then translation (decoding) happens based on that. \n",
        "\n",
        "However, it is clear that, even we as humans will not generate the whole translations without looking back at the _concerned_ parts of the input text. In other words, every translated word is usually generated by _attending_ to certain words in the input, in sequence.\n",
        "\n",
        "So it is better to _condition_ the decoded words on certain words of the input. But who decides which words to attend to when generating/decoding output word?\n",
        "\n",
        "The decoder LSTM will have the following inputs:\n",
        "- previous outputs $y_{t-1}$\n",
        "- state composed of concatenation of:\n",
        "\n",
        "1- previous state $s_{t-1}$ = $[h_{t-1}, C_{t-1}]$\n",
        "\n",
        "2- context vector $c_t$ = weighted/gated encoder states $h_j$ = $\\sum_{j=0}^{j=T} \\alpha_{tj}h_j$ \n",
        "\n",
        "$\\alpha_{tj}$ are the ___attention___ weights. Those can be visualized as the importance of input word $j$ when decoding output word $t$:\n",
        "\n",
        "![att_map](https://miro.medium.com/max/6400/1*T6oosC9Y9vS5AIh4GzcsNQ.png)\n",
        "\n",
        "\n",
        "__How to find those weights?__\n",
        "\n",
        "The alphas can be learnable. However, they must be related somehow to the simialrity between input word $j$ and output word $t$.\n",
        "\n",
        "In the paper [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473), this simialrity measure was _leaned_ using a feedforward NN $a$, which generates a score $e_{tj}$ based on leanable weights over the last decoder state and the encoder state: $e_{tj} = a(s_{t-1}, h_j)$. Those scores are then normalized via simple _softmax_.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDw57pUvUX3E"
      },
      "source": [
        "## Luong attention\n",
        "In [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025), other simialrity measures are studied to encode the _attention map weights_ or $\\alpha_{tj}$. Three simialrity scores $e_{tj}$are studied:\n",
        "- general = weighted dot product\n",
        "- concat = Bahdanau (weighted dot + tanh)\n",
        "- dot = simple dot product\n",
        "\n",
        "Again, the alphas are just simple softmax: $\\alpha_{tj} = softmax(e_{tj})$ over $j \\in [0,T]$ in the encoder state $h_j$\n",
        "Moreover, in Bahdanaus, in Bi-LSTM, both directions states are concatenated. While in Luong, only the top one is used.\n",
        "\n",
        "![Luing_vs_Bahdanau](https://miro.medium.com/max/1184/1*KBKsDHiUBM__dxRV31wZpw.png)\n",
        "\n",
        "In our experiments, we adopt the simpler Luong, with dot configuration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcSw55d3Fyer"
      },
      "source": [
        "emb_sz = 256"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1yI39ENWoF4"
      },
      "source": [
        "def seq2seq_attention(num_encoder_tokens, num_decoder_tokens, emb_sz, latent_dim):\n",
        "    # Define an input sequence and process it.\n",
        "    encoder_inputs = Input(shape=(None,), dtype='float32')\n",
        "    encoder_inputs_ = Embedding(num_encoder_tokens, emb_sz, mask_zero=True)(encoder_inputs)    \n",
        "    \n",
        "    encoder = Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True)) # init LSTM  forword and LSTM backword\n",
        "    encoder_outputs, state_f_h, state_f_c, state_b_h, state_b_c = encoder(encoder_inputs_)# Bi LSTM\n",
        "    state_h = Concatenate()([state_f_h, state_b_h])# Bi LSTM\n",
        "    state_c = Concatenate()([state_f_c, state_b_c])# Bi LSTM\n",
        "\n",
        "    # We discard `encoder_outputs` and only keep the states.\n",
        "    encoder_states = [state_h, state_c]# Bi GRU, LSTM, BHi LSTM\n",
        "    \n",
        "    decoder_inputs = Input(shape=(None,))\n",
        "    decoder_inputs_ = Embedding(num_decoder_tokens, emb_sz, mask_zero=True)(decoder_inputs)    \n",
        "    # We set up our decoder to return full output sequences,\n",
        "    # and to return internal states as well. We don't use the\n",
        "    # return states in the training model, but we will use them in inference.\n",
        "    decoder_lstm = LSTM(latent_dim*2, return_sequences=True, return_state=True)# Bi LSTM\n",
        "    \n",
        "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs_, initial_state=encoder_states)\n",
        "\n",
        "    # Equation (7) with 'dot' score from Section 3.1 in the paper.\n",
        "    # Note that we reuse Softmax-activation layer instead of writing tensor calculation\n",
        "    \n",
        "    att_dot = Dot(axes=[2, 2])\n",
        "    attention = att_dot([decoder_outputs, encoder_outputs])\n",
        "    att_activation = Activation('softmax', name='attention')\n",
        "    attention = att_activation(attention)\n",
        "    context_dot = Dot(axes=[2,1])\n",
        "    context = context_dot([attention, encoder_outputs])\n",
        "    att_context_concat = Concatenate()\n",
        "    decoder_combined_context = att_context_concat([context, decoder_outputs])\n",
        "\n",
        "    # Has another weight + tanh layer as described in equation (5) of the paper\n",
        "\n",
        "    decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "    #decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_outputs = decoder_dense(decoder_combined_context)\n",
        "\n",
        "    # Define the model that will turn\n",
        "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "    print('encoder-decoder  model:')\n",
        "    print(model.summary()) \n",
        "    \n",
        "    encoder_model = Model(encoder_inputs, [encoder_outputs] + encoder_states)\n",
        "\n",
        "    decoder_encoder_inputs = Input(shape=(None, latent_dim*2,)) \n",
        "    decoder_state_input_h = Input(shape=(latent_dim*2,))# Bi LSTM\n",
        "    decoder_state_input_c = Input(shape=(latent_dim*2,)) # Bi LSTM\n",
        "    \n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]# state vector from encoder\n",
        "    \n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_, initial_state=decoder_states_inputs)\n",
        "\n",
        "    \n",
        "    decoder_states = [state_h, state_c]\n",
        "    \n",
        "    # Equation (7) with 'dot' score from Section 3.1 in the paper.\n",
        "    # Note that we reuse Softmax-activation layer instead of writing tensor calculation\n",
        "    \n",
        "    attention = att_dot([decoder_outputs, decoder_encoder_inputs])\n",
        "    \n",
        "    attention = att_activation(attention)\n",
        "    \n",
        "    context = context_dot([attention, decoder_encoder_inputs])\n",
        "    \n",
        "    \n",
        "    \n",
        "    decoder_combined_context = att_context_concat([context, decoder_outputs])\n",
        "    \n",
        "    # Has another weight + tanh layer as described in equation (5) of the paper\n",
        "    \n",
        "    decoder_outputs = decoder_dense(decoder_combined_context)\n",
        "    \n",
        "    decoder_model = Model(\n",
        "        [decoder_inputs, decoder_encoder_inputs] + decoder_states_inputs,\n",
        "        [decoder_outputs, attention] + decoder_states)\n",
        "    \n",
        "    return model, encoder_model, decoder_model"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T79DtmrgLjPQ",
        "outputId": "61688d5c-e301-4250-8189-4214474014c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model, encoder_model, decoder_model = seq2seq_attention(num_encoder_tokens, num_decoder_tokens, emb_sz=emb_sz, latent_dim=emb_sz)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder-decoder  model:\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 256)    517376      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, None, 512),  1050624     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 256)    1145856     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 512)          0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional[0][2]              \n",
            "                                                                 bidirectional[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 512),  1574912     embedding_1[0][0]                \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, None, None)   0           lstm_1[0][0]                     \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "attention (Activation)          (None, None, None)   0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, None, 512)    0           attention[0][0]                  \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, None, 1024)   0           dot_1[0][0]                      \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 4476)   4587900     concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 8,876,668\n",
            "Trainable params: 8,876,668\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 256)    517376      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, None, 512),  1050624     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 256)    1145856     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 512)          0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional[0][2]              \n",
            "                                                                 bidirectional[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 512),  1574912     embedding_1[0][0]                \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, None, None)   0           lstm_1[0][0]                     \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "attention (Activation)          (None, None, None)   0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, None, 512)    0           attention[0][0]                  \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, None, 1024)   0           dot_1[0][0]                      \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 4476)   4587900     concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 8,876,668\n",
            "Trainable params: 8,876,668\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0EseJdCLjSW",
        "outputId": "90aa0f97-8bd7-47e4-d740-70051cd3fcdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=128,\n",
        "          epochs=20,\n",
        "          validation_split=0.05)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "75/75 [==============================] - 29s 145ms/step - loss: 1.4079 - acc: 0.3775 - val_loss: 1.4800 - val_acc: 0.3759\n",
            "Epoch 2/20\n",
            "75/75 [==============================] - 6s 84ms/step - loss: 1.0498 - acc: 0.4894 - val_loss: 1.3601 - val_acc: 0.4549\n",
            "Epoch 3/20\n",
            "75/75 [==============================] - 6s 84ms/step - loss: 0.9055 - acc: 0.5411 - val_loss: 1.2852 - val_acc: 0.4900\n",
            "Epoch 4/20\n",
            "75/75 [==============================] - 6s 84ms/step - loss: 0.8031 - acc: 0.5753 - val_loss: 1.2176 - val_acc: 0.5165\n",
            "Epoch 5/20\n",
            "75/75 [==============================] - 6s 84ms/step - loss: 0.7213 - acc: 0.6002 - val_loss: 1.2076 - val_acc: 0.5336\n",
            "Epoch 6/20\n",
            "75/75 [==============================] - 6s 84ms/step - loss: 0.6522 - acc: 0.6225 - val_loss: 1.1756 - val_acc: 0.5447\n",
            "Epoch 7/20\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 0.5918 - acc: 0.6441 - val_loss: 1.1573 - val_acc: 0.5515\n",
            "Epoch 8/20\n",
            "75/75 [==============================] - 6s 85ms/step - loss: 0.5371 - acc: 0.6645 - val_loss: 1.1520 - val_acc: 0.5461\n",
            "Epoch 9/20\n",
            "75/75 [==============================] - 6s 83ms/step - loss: 0.4885 - acc: 0.6850 - val_loss: 1.1456 - val_acc: 0.5494\n",
            "Epoch 10/20\n",
            "75/75 [==============================] - 6s 83ms/step - loss: 0.4448 - acc: 0.7023 - val_loss: 1.1521 - val_acc: 0.5529\n",
            "Epoch 11/20\n",
            "75/75 [==============================] - 6s 83ms/step - loss: 0.4056 - acc: 0.7217 - val_loss: 1.1371 - val_acc: 0.5597\n",
            "Epoch 12/20\n",
            "75/75 [==============================] - 6s 83ms/step - loss: 0.3699 - acc: 0.7366 - val_loss: 1.1461 - val_acc: 0.5633\n",
            "Epoch 13/20\n",
            "75/75 [==============================] - 6s 83ms/step - loss: 0.3382 - acc: 0.7499 - val_loss: 1.1474 - val_acc: 0.5615\n",
            "Epoch 14/20\n",
            "75/75 [==============================] - 6s 83ms/step - loss: 0.3094 - acc: 0.7678 - val_loss: 1.1376 - val_acc: 0.5751\n",
            "Epoch 15/20\n",
            "75/75 [==============================] - 6s 84ms/step - loss: 0.2838 - acc: 0.7806 - val_loss: 1.1464 - val_acc: 0.5665\n",
            "Epoch 16/20\n",
            "75/75 [==============================] - 6s 84ms/step - loss: 0.2605 - acc: 0.7928 - val_loss: 1.1583 - val_acc: 0.5647\n",
            "Epoch 17/20\n",
            "75/75 [==============================] - 6s 83ms/step - loss: 0.2404 - acc: 0.8052 - val_loss: 1.1510 - val_acc: 0.5722\n",
            "Epoch 18/20\n",
            "75/75 [==============================] - 6s 83ms/step - loss: 0.2222 - acc: 0.8147 - val_loss: 1.1580 - val_acc: 0.5687\n",
            "Epoch 19/20\n",
            "75/75 [==============================] - 6s 83ms/step - loss: 0.2072 - acc: 0.8226 - val_loss: 1.1713 - val_acc: 0.5762\n",
            "Epoch 20/20\n",
            "75/75 [==============================] - 6s 82ms/step - loss: 0.1930 - acc: 0.8296 - val_loss: 1.1728 - val_acc: 0.5694\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc5bc15ef50>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y794XPYpKba"
      },
      "source": [
        "def decode_sequence_attention(input_seq, sep=' '):\n",
        "    # Encode the input as state vectors.\n",
        "    encoder_outputs, h, c = encoder_model.predict(input_seq)\n",
        "    states_value = [h,c]\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index[st_tok]\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    \n",
        "    attention_density = []\n",
        "    \n",
        "    while not stop_condition:\n",
        "        output_tokens, attention, h, c  = decoder_model.predict(\n",
        "            [target_seq, encoder_outputs] + states_value)\n",
        "        attention_density.append(attention[0][0])# attention is max_sent_len x 1 since we have num_time_steps = 1 for the output\n",
        "        # Sample a token\n",
        "        print('++++++++++++++++++++++++++++++++')\n",
        "        print('output_tokens: ',output_tokens)\n",
        "        print('--------------------------------')\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        print('sampled_token_index : ',sampled_token_index)\n",
        "        sampled_tok = reverse_target_tok_index[sampled_token_index]\n",
        "        print('================================')\n",
        "        print('sampled_tok : ',sampled_tok)\n",
        "        decoded_sentence += sep + sampled_tok\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_tok == end_tok or\n",
        "           len(decoded_sentence) > 52):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    attention_density = np.array(attention_density)\n",
        "    print('====================')\n",
        "    print('attention_density : ',attention_density)\n",
        "    return decoded_sentence, attention_density"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A7PJmlsssuE",
        "outputId": "2b7d6570-64ad-447b-ee9f-e96bed5729d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_decoded_sents = []\n",
        "for seq_index in range(5): #[14077,20122,40035,40064, 40056, 40068, 40090, 40095, 40100, 40119, 40131, 40136, 40150, 40153]:\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence, attention = decode_sequence_attention(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', lines.input[seq_index: seq_index + 1])\n",
        "    print('Decoded sentence:', decoded_sentence)\n",
        "    word_decoded_sents.append(decoded_sentence)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[2.84576274e-09 1.09485455e-07 1.02550011e-07 ... 6.61186368e-06\n",
            "   7.47031982e-06 1.33756243e-04]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  4184\n",
            "================================\n",
            "sampled_tok :  va\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[4.5718851e-10 2.7628603e-08 3.1290114e-08 ... 4.3029883e-07\n",
            "   1.0578457e-09 2.8898071e-09]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  6\n",
            "================================\n",
            "sampled_tok :  _END\n",
            "====================\n",
            "attention_density :  [[1.0000000e+00 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26]\n",
            " [1.0000000e+00 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15]]\n",
            "-\n",
            "Input sentence: 0    go\n",
            "Name: input, dtype: object\n",
            "Decoded sentence:  va _END\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[2.84576274e-09 1.09485455e-07 1.02550011e-07 ... 6.61186368e-06\n",
            "   7.47031982e-06 1.33756243e-04]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  4184\n",
            "================================\n",
            "sampled_tok :  va\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[4.5718851e-10 2.7628603e-08 3.1290114e-08 ... 4.3029883e-07\n",
            "   1.0578457e-09 2.8898071e-09]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  6\n",
            "================================\n",
            "sampled_tok :  _END\n",
            "====================\n",
            "attention_density :  [[1.0000000e+00 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26]\n",
            " [1.0000000e+00 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15]]\n",
            "-\n",
            "Input sentence: 1    go\n",
            "Name: input, dtype: object\n",
            "Decoded sentence:  va _END\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[2.84576274e-09 1.09485455e-07 1.02550011e-07 ... 6.61186368e-06\n",
            "   7.47031982e-06 1.33756243e-04]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  4184\n",
            "================================\n",
            "sampled_tok :  va\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[4.5718851e-10 2.7628603e-08 3.1290114e-08 ... 4.3029883e-07\n",
            "   1.0578457e-09 2.8898071e-09]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  6\n",
            "================================\n",
            "sampled_tok :  _END\n",
            "====================\n",
            "attention_density :  [[1.0000000e+00 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26]\n",
            " [1.0000000e+00 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15]]\n",
            "-\n",
            "Input sentence: 2    go\n",
            "Name: input, dtype: object\n",
            "Decoded sentence:  va _END\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[3.7186734e-08 1.4347000e-07 1.7686352e-07 ... 6.0288407e-06\n",
            "   5.7665525e-06 1.2508391e-05]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  3618\n",
            "================================\n",
            "sampled_tok :  salut\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[5.5559973e-08 5.7303648e-11 5.9566137e-11 ... 6.5680156e-11\n",
            "   1.8953715e-13 6.8516533e-15]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  6\n",
            "================================\n",
            "sampled_tok :  _END\n",
            "====================\n",
            "attention_density :  [[1.0000000e+00 1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09\n",
            "  1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09\n",
            "  1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09\n",
            "  1.6660370e-09]\n",
            " [9.9981219e-01 1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05\n",
            "  1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05\n",
            "  1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05\n",
            "  1.2527154e-05]]\n",
            "-\n",
            "Input sentence: 3    hi\n",
            "Name: input, dtype: object\n",
            "Decoded sentence:  salut _END\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[3.7186734e-08 1.4347000e-07 1.7686352e-07 ... 6.0288407e-06\n",
            "   5.7665525e-06 1.2508391e-05]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  3618\n",
            "================================\n",
            "sampled_tok :  salut\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[5.5559973e-08 5.7303648e-11 5.9566137e-11 ... 6.5680156e-11\n",
            "   1.8953715e-13 6.8516533e-15]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  6\n",
            "================================\n",
            "sampled_tok :  _END\n",
            "====================\n",
            "attention_density :  [[1.0000000e+00 1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09\n",
            "  1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09\n",
            "  1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09\n",
            "  1.6660370e-09]\n",
            " [9.9981219e-01 1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05\n",
            "  1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05\n",
            "  1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05\n",
            "  1.2527154e-05]]\n",
            "-\n",
            "Input sentence: 4    hi\n",
            "Name: input, dtype: object\n",
            "Decoded sentence:  salut _END\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc7SuHKXs4Wt"
      },
      "source": [
        "def visualize_attention(text, encoder_model, decoder_model, max_encoder_seq_length, num_decoder_tokens, vocab_to_int, int_to_vocab, tok_split_fn, sep= ' '):\n",
        "\n",
        "    encoder_input_data = np.zeros((1, max_encoder_seq_length), dtype='float32')\n",
        "    \n",
        "    for t, word in enumerate(tok_split_fn(text)):\n",
        "        encoder_input_data[0, t] = input_token_index[word]\n",
        "\n",
        "    input_seq = encoder_input_data[0:1]\n",
        "\n",
        "    decoded_sentence, attention_density = decode_sequence_attention(input_seq, sep)\n",
        "\n",
        "    plt.clf()\n",
        "    plt.figure(figsize=(28,12))\n",
        "    \n",
        "    ax = sns.heatmap(attention_density[:, : len(text) + 2],\n",
        "        xticklabels=[w for w in tok_split_fn(text)],\n",
        "        yticklabels=[w for w in tok_split_fn(decoded_sentence)])\n",
        "\n",
        "    ax.invert_yaxis()\n",
        "    plt.show()\n",
        "    \n",
        "    return decoded_sentence"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cZdduoTvw54",
        "outputId": "5aea1877-3faf-457e-a2f7-c208b3125405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for seq_index in range(5):\n",
        "\n",
        "    target_text = lines.target[seq_index]\n",
        "    text = lines.input[seq_index]\n",
        "    print('-')\n",
        "    print('Input sentence:', text)    \n",
        "    print('GT sentence:', target_text)\n",
        "    decoded_sentence = visualize_attention(text, encoder_model, decoder_model, max_encoder_seq_length, num_decoder_tokens, input_token_index, reverse_target_tok_index, tok_split_fn)\n",
        "\n",
        "    \n",
        "    print('Decoded sentence:', decoded_sentence)   \n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input sentence: go\n",
            "GT sentence: START_ va  _END\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[2.84576274e-09 1.09485455e-07 1.02550011e-07 ... 6.61186368e-06\n",
            "   7.47031982e-06 1.33756243e-04]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  4184\n",
            "================================\n",
            "sampled_tok :  va\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[4.5718851e-10 2.7628603e-08 3.1290114e-08 ... 4.3029883e-07\n",
            "   1.0578457e-09 2.8898071e-09]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  6\n",
            "================================\n",
            "sampled_tok :  _END\n",
            "====================\n",
            "attention_density :  [[1.0000000e+00 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26]\n",
            " [1.0000000e+00 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2016x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded sentence:  va _END\n",
            "-\n",
            "Input sentence: go\n",
            "GT sentence: START_ marche _END\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[2.84576274e-09 1.09485455e-07 1.02550011e-07 ... 6.61186368e-06\n",
            "   7.47031982e-06 1.33756243e-04]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  4184\n",
            "================================\n",
            "sampled_tok :  va\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[4.5718851e-10 2.7628603e-08 3.1290114e-08 ... 4.3029883e-07\n",
            "   1.0578457e-09 2.8898071e-09]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  6\n",
            "================================\n",
            "sampled_tok :  _END\n",
            "====================\n",
            "attention_density :  [[1.0000000e+00 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26]\n",
            " [1.0000000e+00 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2016x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded sentence:  va _END\n",
            "-\n",
            "Input sentence: go\n",
            "GT sentence: START_ bouge  _END\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[2.84576274e-09 1.09485455e-07 1.02550011e-07 ... 6.61186368e-06\n",
            "   7.47031982e-06 1.33756243e-04]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  4184\n",
            "================================\n",
            "sampled_tok :  va\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[4.5718851e-10 2.7628603e-08 3.1290114e-08 ... 4.3029883e-07\n",
            "   1.0578457e-09 2.8898071e-09]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  6\n",
            "================================\n",
            "sampled_tok :  _END\n",
            "====================\n",
            "attention_density :  [[1.0000000e+00 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26 1.1343488e-26\n",
            "  1.1343488e-26]\n",
            " [1.0000000e+00 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15 8.5344236e-15\n",
            "  8.5344236e-15]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2016x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded sentence:  va _END\n",
            "-\n",
            "Input sentence: hi\n",
            "GT sentence: START_ salut  _END\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[3.7186734e-08 1.4347000e-07 1.7686352e-07 ... 6.0288407e-06\n",
            "   5.7665525e-06 1.2508391e-05]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  3618\n",
            "================================\n",
            "sampled_tok :  salut\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[5.5559973e-08 5.7303648e-11 5.9566137e-11 ... 6.5680156e-11\n",
            "   1.8953715e-13 6.8516533e-15]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  6\n",
            "================================\n",
            "sampled_tok :  _END\n",
            "====================\n",
            "attention_density :  [[1.0000000e+00 1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09\n",
            "  1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09\n",
            "  1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09\n",
            "  1.6660370e-09]\n",
            " [9.9981219e-01 1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05\n",
            "  1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05\n",
            "  1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05\n",
            "  1.2527154e-05]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABYcAAAKvCAYAAAAx0HA6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdf6zv910X8OernbVTBmg2dWurVNIZK2qoy9wYZD+N3RZbIhNbNQtkcjVxxAQZjghT649EB/6hjh8XUhdM3DKVkEsoqQkpIxIG7cAttnOmKUpbl9TBAGWB/vi8/OOekuP13vM9Zz3nvM/19XgkJzvfH+dzX9v+e+WZ56u6OwAAAAAAzHLN6gEAAAAAADh9lsMAAAAAAANZDgMAAAAADGQ5DAAAAAAwkOUwAAAAAMBAlsMAAAAAAANZDgMAAAAAnHFVdW9VPVVV//kKn1dV/fOqerSqPllVt+16puUwAAAAAMDZ98Ektx/w+VuT3LL3cy7J9+56oOUwAAAAAMAZ190/leRXDvjKnUl+qC/6WJIvraqXH/TMFx3ngFfyzGcf69P4dwBO24tf8TWrRwAAAIDf9uzTT9bqGa5GZ2F/ed3Lvvyv5WLi93nnu/v8ER5xQ5LH971+Yu+9z1zpD05lOQwAAAAAwJXtLYKPsgx+wdRKAAAAAABc/Z5MctO+1zfuvXdFlsMAAAAAAFe/C0neWRe9JsmvdfcVKyUStRIAAAAAwHTbc6sn2KmqPpTkDUleWlVPJPm7SX5HknT39yW5L8nbkjya5PNJvnHXMy2HAQAAAADOuO6+e8fnneRvHOWZlsMAAAAAwGy9rZ5gCZ3DAAAAAAADWQ4DAAAAAAykVgIAAAAAmG1TKwEAAAAAwBCSwwAAAADAaO0gHQAAAAAAU1gOAwAAAAAMpFYCAAAAAJjNQToAAAAAAKaQHAYAAAAAZnOQDgAAAACAKSyHAQAAAAAGUisBAAAAAMy2Pbd6giUkhwEAAAAABpIcBgAAAABmc5AOAAAAAIApLIcBAAAAAAZSKwEAAAAAzLaplQAAAAAAYAjJYQAAAABgtHaQDgAAAACAKSyHAQAAAAAGUisBAAAAAMzmIB0AAAAAAFNYDgMAAAAADKRWAgAAAACYrdVKAAAAAAAwhOQwAAAAADDb9tzqCZaQHAYAAAAAGMhyGAAAAABgILUSAAAAAMBsDtIBAAAAADCF5DAAAAAAMNsmOQwAAAAAwBCWwwAAAAAAA6mVAAAAAABmc5AOAAAAAIApJIcBAAAAgNkcpAMAAAAAYArLYQAAAACAgdRKAAAAAACjdT+3eoQlJIcBAAAAAAaSHAYAAAAAZmsH6QAAAAAAGMJyGAAAAABgILUSAAAAAMBsm1oJAAAAAACGkBwGAAAAAGZzkA4AAAAAgCkshwEAAAAABlIrAQAAAADMtj23eoIlJIcBAAAAAAayHAYAAAAAGEitBAAAAAAwW2+rJ1hCchgAAAAAYCDJYQAAAABgtk1yGAAAAACAISyHAQAAAAAGUisBAAAAAMzmIB0AAAAAAFNIDgMAAAAAszlIBwAAAADAFJbDAAAAAAADqZUAAAAAAGZTKwEAAAAAwBSSwwAAAADAaN3PrR5hCclhAAAAAICBLIcBAAAAAAZSKwEAAAAAzOYgHQAAAAAAU0gOAwAAAACzteQwAAAAAABDWA4DAAAAAAykVgIAAAAAmM1BOgAAAAAAprAcBgAAAAAYSK0EAAAAADBbq5UAAAAAAGAIyWEAAAAAYDYH6QAAAAAAmMJyGAAAAABgILUSAAAAAMBsDtIBAAAAADCF5DAAAAAAMJuDdAAAAAAATGE5DAAAAAAwkFoJAAAAAGA2tRIAAAAAAEwhOQwAAAAAzNaSwwAAAAAADGE5DAAAAAAwkFoJAAAAAGA2B+kAAAAAAJhCchgAAAAAmM1BOgAAAAAAprAcBgAAAAAYSK0EAAAAADCbg3QAAAAAAEwhOQwAAAAAzOYgHQAAAAAAU1gOAwAAAAAMpFYCAAAAAJjNQToAAAAAAKawHAYAAAAAGEitBAAAAAAwm1oJAAAAAACmkBwGAAAAAGbrXj3BEpLDAAAAAAADWQ4DAAAAAAykVgIAAAAAmM1BOgAAAAAAppAcBgAAAABmkxwGAAAAAGAKy2EAAAAAgIHUSgAAAAAAs7VaCQAAAAAAhpAcBgAAAABmc5AOAAAAAIApLIcBAAAAAAZSKwEAAAAAzNa9eoIlJIcBAAAAAAayHAYAAAAAZtu29T87VNXtVfXpqnq0qt57mc//YFU9UFW/UFWfrKq37Xqm5TAAAAAAwBlWVdcm+UCStya5NcndVXXrJV/7jiQf6e6vTHJXku/Z9VzLYQAAAACAs+3VSR7t7se6++kkH05y5yXf6SRfvPf7lyT5H7se6iAdAAAAADDbIWodTlpVnUtybt9b57v7/N7vNyR5fN9nTyT505c84u8l+Q9V9c1JfneSt+z6Ny2HAQAAAAAW21sEn9/5xSu7O8kHu/u7q+q1Sf51VX1Fd19x8205DAAAAADMduX96VnxZJKb9r2+ce+9/d6V5PYk6e6fqarrk7w0yVNXeqjOYQAAAACAs+3BJLdU1c1VdV0uHpy7cMl3finJm5Okqv5okuuT/M+DHmo5DAAAAABwhnX3s0neneT+JJ9K8pHufriq7qmqO/a+9reSfFNVfSLJh5J8Q3f3Qc9VKwEAAAAAjNbbgTvUM6G770ty3yXvvW/f748ked1Rnik5DAAAAAAwkOUwAAAAAMBAaiUAAAAAgNm2bfUES0gOAwAAAAAMJDkMAAAAAMzWksMAAAAAAAxhOQwAAAAAMJBaCQAAAABgtq1XT7CE5DAAAAAAwECSwwAAAADAbJuDdAAAAAAADGE5DAAAAAAwkFoJAAAAAGA2tRIAAAAAAEwhOQwAAAAAzNa9eoIlJIcBAAAAAAayHAYAAAAAGEitBAAAAAAwm4N0AAAAAABMITkMAAAAAMy2OUgHAAAAAMAQlsMAAAAAAAOplQAAAAAAZmsH6QAAAAAAGMJyGAAAAABgoJ21ElX1xiTfnOSP7L31qST/srt/8gTnAgAAAAA4HVuvnmCJA5PDVfX2JPcm+dEkfynJX05yX5J7q+ptJz8eAAAAAAAnYVetxHuSfG13/6vu/kR3/6fuvjfJ1yb52wf9YVWdq6qHquqhH/yhDx3XvAAAAAAAx6q3bfnPCrtqJf5Ad3/i0je7+5NV9fsP+sPuPp/kfJI889nHZuayAQAAAADOqF3J4d/4Aj8DAAAAAOAM25Uc/vKqunCZ9yvJHz6BeQAAAAAATtfQg3S7lsN3HvDZdx3nIAAAAAAAnJ4Dl8Pd/dHTGgQAAAAAYIlecxButQOXw1X1QJIrZaq7u998/CMBAAAAAHDSdtVKfOtl3ntNkm9L8tTxjwMAAAAAwGnYVSvx8ed/r6rXJ/nOJNcn+evd/eMnPBsAAAAAwMlzkO7yqurPJvmOJL+V5B919wMnPhUAAAAAACdqV+fwg0leluT9SX5m773bnv+8u3/+RKcDAAAAADhpm4N0l/MbSf53knfs/ezXSd50EkMBAAAAAHCydnUOv+GU5gAAAAAA4BRdc9CHVfVt+37/C5d89o9PaigAAAAAgFOz9fqfBQ5cDie5a9/v337JZ7cf8ywAAAAAAJySXZ3DdYXfL/caAAAAAODq0zMP0u1KDvcVfr/cawAAAAAArhK7ksN/sqp+PRdTwi/e+z17r69//ktV9Xu6+3MnNCMAAAAAAMfswOVwd197yOf8RJLbXvg4AAAAAACnbNFBuNV21Uoclv5hAAAAAICryK5aicOauVoHAAAAAK56vTlIBwAAAADAEGolAAAAAAAGOq5aiTcf03MAAAAAAE6Xg3RfuO7+leN4DgAAAAAAp0PnMAAAAADAQMdVKwEAAAAAcHVSKwEAAAAAwBSSwwAAAADAbL2tnmAJyWEAAAAAgIEshwEAAAAABlIrAQAAAADM5iAdAAAAAABTSA4DAAAAAKO15DAAAAAAAFNYDgMAAAAADKRWAgAAAACYTa0EAAAAAABTSA4DAAAAALNt2+oJlpAcBgAAAAAYyHIYAAAAAGAgtRIAAAAAwGwO0gEAAAAAMIXkMAAAAAAwm+QwAAAAAABTWA4DAAAAAAykVgIAAAAAGK1brQQAAAAAAENIDgMAAAAAszlIBwAAAADAFJbDAAAAAAADqZUAAAAAAGZTKwEAAAAAwBSWwwAAAAAAA6mVAAAAAABGa7USAAAAAABMITkMAAAAAMwmOQwAAAAAwBSWwwAAAAAAA6mVAAAAAABm21YPsIbkMAAAAADAQJLDAAAAAMBo7SAdAAAAAABTWA4DAAAAAAykVgIAAAAAmE2tBAAAAAAAU0gOAwAAAACzbasHWENyGAAAAABgIMthAAAAAICB1EoAAAAAAKO1g3QAAAAAAEwhOQwAAAAAzOYgHQAAAAAAU1gOAwAAAAAMpFYCAAAAABjNQToAAAAAAMawHAYAAAAAGEitBAAAAAAw27Z6gDUkhwEAAAAABpIcBgAAAABGa8lhAAAAAACmsBwGAAAAABhIrQQAAAAAMJtaCQAAAAAAppAcBgAAAABGc5AOAAAAAIAxLIcBAAAAAAZSKwEAAAAAzKZWAgAAAACAKSSHAQAAAIDRHKQDAAAAAGAMy2EAAAAAgIHUSgAAAAAAo6mVAAAAAABgDMthAAAAAGC03tb/7FJVt1fVp6vq0ap67xW+8/VV9UhVPVxV/2bXM9VKAAAAAACcYVV1bZIPJPkzSZ5I8mBVXejuR/Z955Yk357kdd39uar6fbueKzkMAAAAAHC2vTrJo939WHc/neTDSe685DvflOQD3f25JOnup3Y91HIYAAAAAJita/lPVZ2rqof2/ZzbN+ENSR7f9/qJvff2e2WSV1bVT1fVx6rq9l3/tdVKAAAAAAAs1t3nk5x/AY94UZJbkrwhyY1Jfqqq/nh3/+pBfwAAAAAAMNZhDsIt9mSSm/a9vnHvvf2eSPKz3f1Mkl+sqv+ai8viB6/0ULUSAAAAAABn24NJbqmqm6vquiR3JblwyXd+JBdTw6mql+ZizcRjBz3UchgAAAAA4Azr7meTvDvJ/Uk+leQj3f1wVd1TVXfsfe3+JL9cVY8keSDJe7r7lw96bnX3Sc6dJHnms4+d/D8CsMCLX/E1q0cAAACA3/bs00/W6hmuRp/56jcu31++/D8+cOr/30kOAwAAAAAMZDkMAAAAADDQi1YPAAAAAACwUm+rJ1hDchgAAAAAYCDJYQAAAABgtO6Zd/wkhwEAAAAABrIcBgAAAAAYSK0EAAAAADCag3QAAAAAAIwhOQwAAAAAjNabg3QAAAAAAAxhOQwAAAAAMJBaCQAAAABgtO7VE6whOQwAAAAAMJDkMAAAAAAwmoN0AAAAAACMYTkMAAAAADCQWgkAAAAAYDS1EgAAAAAAjCE5DAAAAACM1r16gjUkhwEAAAAABrIcBgAAAAAYSK0EAAAAADCag3QAAAAAAIwhOQwAAAAAjNYtOQwAAAAAwBCWwwAAAAAAA6mVAAAAAABG6231BGtIDgMAAAAADGQ5DAAAAAAwkFoJAAAAAGC0rWv1CEtIDgMAAAAADCQ5DAAAAACM1pLDAAAAAABMYTkMAAAAADCQWgkAAAAAYLTe1EoAAAAAADCE5DAAAAAAMFr36gnWkBwGAAAAABjIchgAAAAAYCC1EgAAAADAaA7SAQAAAAAwhuQwAAAAADDa1pLDAAAAAAAMYTkMAAAAADCQWgkAAAAAYLRWKwEAAAAAwBSSwwAAAADAaN2rJ1hDchgAAAAAYCDLYQAAAACAgdRKAAAAAACjbQ7SAQAAAAAwheQwAAAAADBaSw4DAAAAADCF5TAAAAAAwEBqJQAAAACA0bpXT7CG5DAAAAAAwECWwwAAAAAAA6mVAAAAAABG27pWj7CE5DAAAAAAwECSwwAAAADAaC05DAAAAADAFJbDAAAAAAADqZUAAAAAAEZzkA4AAAAAgDEkhwEAAACA0Xr1AItIDgMAAAAADGQ5DAAAAAAwkFoJAAAAAGA0B+kAAAAAABhDchgAAAAAGK0lhwEAAAAAmMJyGAAAAABgILUSAAAAAMBo2+oBFpEcBgAAAAAYSHIYAAAAABit4yAdAAAAAABDWA4DAAAAAAykVgIAAAAAGG3r1ROsITkMAAAAADCQ5TAAAAAAwEBqJQAAAACA0bbU6hGWkBwGAAAAABhIchgAAAAAGK0lhwEAAAAAmMJyGAAAAABgILUSAAAAAMBo2+oBFpEcBgAAAAAYSHIYAAAAABjNQToAAAAAAMawHAYAAAAAGEitBAAAAAAwmoN0AAAAAACMITkMAAAAAIwmOQwAAAAAwBiWwwAAAAAAA6mVAAAAAABG69TqEZaQHAYAAAAAGEhyGAAAAAAYbZsZHJYcBgAAAACYyHIYAAAAAGAgtRIAAAAAwGibg3QAAAAAAEwhOQwAAAAAjNarB1hEchgAAAAAYCDLYQAAAACAgdRKAAAAAACjbasHWERyGAAAAABgIMthAAAAAICB1EoAAAAAAKNtVatHWEJyGAAAAABgIMlhAAAAAGC0Xj3AIpLDAAAAAAADWQ4DAAAAAAykVgIAAAAAGG1bPcAiksMAAAAAAANJDgMAAAAAo221eoI1JIcBAAAAAAayHAYAAAAAGEitBAAAAAAw2paZvRKSwwAAAAAAA0kOAwAAAACj9eoBFpEcBgAAAAA446rq9qr6dFU9WlXvPeB7X1dVXVWv2vVMy2EAAAAAgDOsqq5N8oEkb01ya5K7q+rWy3zvJUn+ZpKfPcxzLYcBAAAAgNG2Wv+zw6uTPNrdj3X300k+nOTOy3zvHyT5J0l+8zD/vS2HAQAAAAAWq6pzVfXQvp9z+z6+Icnj+14/sffe/r+/LclN3f1jh/03HaQDAAAAAEbbVg+QpLvPJzn/hfxtVV2T5J8l+Yaj/J3kMAAAAADA2fZkkpv2vb5x773nvSTJVyT5yar6b0lek+TCrqN0lsMAAAAAAGfbg0luqaqbq+q6JHclufD8h939a9390u7+su7+siQfS3JHdz900EPVSgAAAAAAo/XqAXbo7mer6t1J7k9ybZJ7u/vhqronyUPdfeHgJ1ye5TAAAAAAwBnX3fclue+S9953he++4TDPtBwGAAAAAEbbavUEa+gcBgAAAAAYyHIYAAAAAGAgtRIAAAAAwGjb6gEWkRwGAAAAABjIchgAAAAAYCC1EgAAAADAaGolAAAAAAAYQ3IYAAAAABita/UEa0gOAwAAAAAMZDkMAAAAADCQWgkAAAAAYDQH6QAAAAAAGENyGAAAAAAYTXIYAAAAAIAxLIcBAAAAAAZSKwEAAAAAjNarB1hEchgAAAAAYCDJYQAAAABgtK1WT7CG5DAAAAAAwECWwwAAAAAAA6mVAAAAAABG21YPsIjkMAAAAADAQJLDAAAAAMBoksMAAAAAAIxhOQwAAAAAMJBaCQAAAABgtF49wCKSwwAAAAAAA1kOAwAAAAAMpFYCAAAAABhtq9UTrCE5DAAAAAAwkOQwAAAAADDatnqARSSHAQAAAAAGshwGAAAAABhIrQQAAAAAMFqvHmARyWEAAAAAgIEkhwEAAACA0bah2WHJYQAAAACAgSyHAQAAAAAGUisBAAAAAIy2rR5gEclhAAAAAICBJIcBAAAAgNFmnqOTHAYAAAAAGMlyGAAAAABgILUSAAAAAMBoDtIBAAAAADCG5DAAAAAAMNpWqydYQ3IYAAAAAGAgy2EAAAAAgIHUSgAAAAAAo23p1SMsITkMAAAAADCQ5DAAAAAAMNrM3LDkMAAAAADASJbDAAAAAAADqZUAAAAAAEbbVg+wiOQwAAAAAMBAlsMAAAAAAAOplQAAAAAARtvSq0dYQnIYAAAAAGAgyWEAAAAAYLSZuWHJYQAAAACAkSyHAQAAAAAGUisBAAAAAIy2rR5gEclhAAAAAICBJIcBAAAAgNG2oSfpJIcBAAAAAAayHAYAAAAAGEitBAAAAAAw2sxSCclhAAAAAICRJIcBAAAAgNG21QMsIjkMAAAAADCQ5TAAAAAAwEBqJQAAAACA0XroSTrJYQAAAACAgSSHAQAAAIDRHKQDAAAAAGAMy2EAAAAAgIHUSgAAAAAAo20O0gEAAAAAMIXkMAAAAAAw2szcsOQwAAAAAMBIlsMAAAAAAAOplQAAAAAARnOQDgAAAACAMSyHAQAAAAAGUisBAAAAAIy2rR5gEclhAAAAAICBJIcBAAAAgNHaQToAAAAAAKawHAYAAAAAGOjQy+Gqet1h3gMAAAAAuJpsZ+BnhaMkh//FId8DAAAAAOCM23mQrqpem+Srkrysqr5l30dfnOTaA/7uXJJzSfI93/0P81ffefcLHBUAAAAA4PhNPUi3czmc5LokX7T33Zfse//Xk7zjSn/U3eeTnE+SZz772Mz/dQEAAAAAzqidy+Hu/miSj1bVB7v7v5/CTAAAAAAAnLDDJIef98Gq+n8SwN39pmOcBwAAAADgVK06CLfaUZbD37rv9+uTfF2SZ493HAAAAAAATsOhl8Pd/fFL3vrpqvq5Y54HAAAAAOBUbT3zZNqhl8NV9Xv3vbwmyZ9K8iXHPhEAAAAAACfuKLUSH0/SSSoX6yR+Mcm7TmIoAAAAAABO1lFqJW4+yUEAAAAAAFaYWSpxiOVwVf35gz7v7h8+vnEAAAAAADgNh0kO/7kDPusklsMAAAAAwFVrG5od3rkc7u5vPI1BAAAAAAA4PUc5SJeqenuSP5bk+uff6+57jnsoAAAAAABO1qGXw1X1fUl+V5I3JvnBJO9I8nMnNBcAAAAAwKnoobUS1xzhu1/V3e9M8rnu/vtJXpvklSczFgAAAAAAJ+koy+Hf3PvPz1fVK5I8m+Tlxz8SAAAAAAAn7Sidwz9aVV+a5P1Jfj5JJ/mBE5kKAAAAAOCUbKsHWOQoy+H/kuS57v73VXVrktuS/MjJjAUAAAAAwEk6Sq3Ed3b3/6qqr07yplw8Sve9JzMWAAAAAMDp2NLLf1Y4ynL4ub3/fHuSH+juH0ty3fGPBAAAAADASTvKcvjJqvr+JH8xyX1V9TuP+PcAAAAAAJwRR+kc/voktyf5ru7+1ap6eZL3nMxYAAAAAACnoxfVOqx26OVwd38+yQ/ve/2ZJJ85iaEAAAAAADhZR0kOAwAAAAD8f2dbPcAiOoMBAAAAAAayHAYAAAAAGEitBAAAAAAwWvfMg3SSwwAAAAAAA0kOAwAAAACjbZEcBgAAAADgDKqq26vq01X1aFW99zKff0tVPVJVn6yqn6iqP7TrmZbDAAAAAABnWFVdm+QDSd6a5NYkd1fVrZd87ReSvKq7/0SSf5fkn+56ruUwAAAAADDadgZ+dnh1kke7+7HufjrJh5Pcuf8L3f1Ad39+7+XHkty466GWwwAAAAAAi1XVuap6aN/PuX0f35Dk8X2vn9h770releTHd/2bDtIBAAAAAKP1GThI193nk5x/oc+pqr+S5FVJXr/ru5bDAAAAAABn25NJbtr3+sa99/4vVfWWJH8nyeu7+7d2PVStBAAAAADA2fZgkluq6uaqui7JXUku7P9CVX1lku9Pckd3P3WYh0oOAwAAAACjbWegVuIg3f1sVb07yf1Jrk1yb3c/XFX3JHmouy8keX+SL0ryb6sqSX6pu+846LmWwwAAAAAAZ1x335fkvkvee9++399y1GdaDgMAAAAAo3Wf7eTwSdE5DAAAAAAwkOUwAAAAAMBAaiUAAAAAgNG21QMsIjkMAAAAADCQ5TAAAAAAwEBqJQAAAACA0Tq9eoQlJIcBAAAAAAaSHAYAAAAARtskhwEAAAAAmMJyGAAAAABgILUSAAAAAMBo3WolAAAAAAAYQnIYAAAAABjNQToAAAAAAMawHAYAAAAAGEitBAAAAAAwWquVAAAAAABgCslhAAAAAGC0rSWHAQAAAAAYwnIYAAAAAGAgtRIAAAAAwGgzSyUkhwEAAAAARpIcBgAAAABG24ZmhyWHAQAAAAAGshwGAAAAABhIrQQAAAAAMJpaCQAAAAAAxpAcBgAAAABG65YcBgAAAABgCMthAAAAAICB1EoAAAAAAKM5SAcAAAAAwBiWwwAAAAAAA6mVAAAAAABGa7USAAAAAABMITkMAAAAAIzWLTkMAAAAAMAQlsMAAAAAAAOplQAAAAAARtscpAMAAAAAYArJYQAAAABgNAfpAAAAAAAYw3IYAAAAAGAgtRIAAAAAwGgO0gEAAAAAMIbkMAAAAAAwWksOAwAAAAAwheUwAAAAAMBAaiUAAAAAgNG2VisBAAAAAMAQksMAAAAAwGgO0gEAAAAAMIblMAAAAADAQGolAAAAAIDRHKQDAAAAAGAMyWEAAAAAYDQH6QAAAAAAGMNyGAAAAABgILUSAAAAAMBoDtIBAAAAADCG5TAAAAAAwEBqJQAAAACA0TpqJQAAAAAAGEJyGAAAAAAYzUE6AAAAAADGsBwGAAAAABhIrQQAAAAAMJqDdAAAAAAAjCE5DAAAAACM1r2tHmEJyWEAAAAAgIEshwEAAAAABlIrAQAAAACMtjlIBwAAAADAFJLDAAAAAMBo3ZLDAAAAAAAMYTkMAAAAADCQWgkAAAAAYDQH6QAAAAAAGENyGAAAAAAYzUE6AAAAAADGsBwGAAAAABhIrQQAAAAAMNqmVgIAAAAAgCkshwEAAAAABlIrAQAAAACM1lErAQAAAADAEJLDAAAAAMBo7SAdAAAAAABTWA4DAAAA/6e9O7SpKIiCALo3YOgCg6INOoAafhkIesCAoQ56IEGApgUsgn8xCAQEBfuyc456eerqyWQWgEBmJQAAAACAaHsP0gEAAAAAkEJzGAAAAACI5kE6AAAAAABiCIcBAAAAAAKZlQAAAAAAou3NSgAAAAAAkEJzGAAAAACI5kE6AAAAAABiCIcBAAAAAAKZlQAAAAAAou2HWQkAAAAAAEJoDgMAAAAA0TxIBwAAAABADOEwAAAAAEAgsxIAAAAAQLS9WQkAAAAAAFJoDgMAAAAA0XpoDgMAAAAAEEI4DAAAAAAQyKwEAAAAACuJIFYAAAGmSURBVBDNg3QAAAAAAMQQDgMAAAAABDIrAQAAAABEa7MSAAAAAACk0BwGAAAAAKL10BwGAAAAACCEcBgAAAAAIJBZCQAAAAAgmgfpAAAAAACIoTkMAAAAAETTHAYAAAAAIIZwGAAAAAAgkFkJAAAAACBa5qiE5jAAAAAAQKRKHVtmXVW16+6b2XcAAAAAwJZpDrOi3ewDAAAAAGDrhMMAAAAAAIGEwwAAAAAAgYTDrMjeMAAAAAD8woN0AAAAAACBNIcBAAAAAAIJhwEAAAAAAgmHWUJVHVfV0zf/r6rqbMZNAAAAALBlh7MPgL/U3ZezbwAAAACALdIcZiUHVXVbVc9VdV9VR1V1V1UXsw8DAAAAgK0RDrOSkzHGdXefjjFexxjnk+8BAAAAgM0SDrOSl+5+/Px+GGMcT7wFAAAAADZNOMxK3r58vw+b2gAAAADwI+EwAAAAAEAg4TAAAAAAQKDq7tk3AAAAAADwzzSHAQAAAAACCYcBAAAAAAIJhwEAAAAAAgmHAQAAAAACCYcBAAAAAAIJhwEAAAAAAgmHAQAAAAACfQBhNHS6ja8b1AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 2016x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded sentence:  salut _END\n",
            "-\n",
            "Input sentence: hi\n",
            "GT sentence: START_ salut _END\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[3.7186734e-08 1.4347000e-07 1.7686352e-07 ... 6.0288407e-06\n",
            "   5.7665525e-06 1.2508391e-05]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  3618\n",
            "================================\n",
            "sampled_tok :  salut\n",
            "++++++++++++++++++++++++++++++++\n",
            "output_tokens:  [[[5.5559973e-08 5.7303648e-11 5.9566137e-11 ... 6.5680156e-11\n",
            "   1.8953715e-13 6.8516533e-15]]]\n",
            "--------------------------------\n",
            "sampled_token_index :  6\n",
            "================================\n",
            "sampled_tok :  _END\n",
            "====================\n",
            "attention_density :  [[1.0000000e+00 1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09\n",
            "  1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09\n",
            "  1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09 1.6660370e-09\n",
            "  1.6660370e-09]\n",
            " [9.9981219e-01 1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05\n",
            "  1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05\n",
            "  1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05 1.2527154e-05\n",
            "  1.2527154e-05]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2016x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded sentence:  salut _END\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLJFJDhPv2YY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}